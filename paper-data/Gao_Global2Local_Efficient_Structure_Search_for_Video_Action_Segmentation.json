{
  "arXiv": "http://arxiv.org/abs/2101.00910",
  "title": "Global2Local: Efficient Structure Search for Video Action Segmentation",
  "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Gao_Global2Local_Efficient_Structure_Search_for_Video_Action_Segmentation_CVPR_2021_paper.pdf",
  "authors": [
    "Shang-Hua Gao",
    "Qi Han",
    "Zhong-Yu Li",
    "Pai Peng",
    "Liang Wang",
    "Ming-Ming Cheng"
  ],
  "abstract": "Temporal receptive fields of models play an important role in action segmentation. Large receptive fields facilitate the long-term relations among video clips while small receptive fields help capture the local details. Existing methods construct models with hand-designed receptive fields in layers. Can we effectively search for receptive field combinations to replace hand-designed patterns? To answer this question, we propose to find better receptive field combinations through a global-to-local search scheme. Our search scheme exploits both global search to find the coarse combinations and local search to get the refined receptive field combination patterns further. The global search finds possible coarse combinations other than human-designed patterns. On top of the global search, we propose an expectation guided iterative local search scheme to refine combinations effectively. Our global-to-local search can be plugged into existing action segmentation methods to achieve state-of-the-art performance. The source code is publicly available on http://mmcheng.net/g2lsearch.",
  "s2id": "1a617a58ab3f80a7d78fca9e0f6497ce4a5314eb",
  "citations": 3,
  "posterSession": "Friday"
}