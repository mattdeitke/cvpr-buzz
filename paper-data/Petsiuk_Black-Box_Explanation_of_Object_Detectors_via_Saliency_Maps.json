{
  "arXiv": "http://arxiv.org/abs/2006.03204",
  "title": "Black-Box Explanation of Object Detectors via Saliency Maps",
  "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Petsiuk_Black-Box_Explanation_of_Object_Detectors_via_Saliency_Maps_CVPR_2021_paper.pdf",
  "authors": [
    "Vitali Petsiuk",
    "Rajiv Jain",
    "Varun Manjunatha",
    "Vlad I. Morariu",
    "Ashutosh Mehra",
    "Vicente Ordonez",
    "Kate Saenko"
  ],
  "abstract": "We propose D-RISE, a method for generating visual explanations for the predictions of object detectors. Utilizing the proposed similarity metric that accounts for both localization and categorization aspects of object detection allows our method to produce saliency maps that show image areas that most affect the prediction. D-RISE can be considered \"black-box\" in the software testing sense, as it only needs access to the inputs and outputs of an object detector. Compared to gradient-based methods, D-RISE is more general and agnostic to the particular type of object detector being tested, and does not need knowledge of the inner workings of the model. We show that D-RISE can be easily applied to different object detectors including one-stage detectors such as YOLOv3 and two-stage detectors such as Faster-RCNN. We present a detailed analysis of the generated visual explanations to highlight the utilization of context and possible biases learned by object detectors.",
  "s2id": "6db706ee5a3ff905a34b78189596c833c00124aa",
  "twitter": {
    "retweets": 6,
    "likes": 15,
    "replies": 3
  },
  "citations": 3,
  "posterSession": "Thursday"
}