{
  "arXiv": "http://arxiv.org/abs/2006.02635",
  "title": "M3P: Learning Universal Representations via Multitask Multilingual Multimodal Pre-Training",
  "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Ni_M3P_Learning_Universal_Representations_via_Multitask_Multilingual_Multimodal_Pre-Training_CVPR_2021_paper.pdf",
  "authors": [
    "Minheng Ni",
    "Haoyang Huang",
    "Lin Su",
    "Edward Cui",
    "Taroon Bharti",
    "Lijuan Wang",
    "Dongdong Zhang",
    "Nan Duan"
  ],
  "abstract": "We present M3P, a Multitask Multilingual Multimodal Pre-trained model that combines multilingual pre-training and multimodal pre-training into a unified framework via multitask pre-training. Our goal is to learn universal representations that can map objects occurred in different modalities or texts expressed in different languages into a common semantic space. In addition, to explicitly encourage fine-grained alignment between images and non-English languages, we also propose Multimodal Code-switched Training (MCT) to combine monolingual pre-training and multimodal pre-training via a code-switch strategy. Experiments are performed on the multilingual image retrieval task across two benchmark datasets, including MSCOCO and Multi30K. M3P can achieve comparable results for English and new state-of-the-art results for non-English languages.",
  "s2id": "9960d13255259c66812dd130e08c17720ff60c18",
  "twitter": {
    "retweets": 2,
    "likes": 20,
    "replies": 2,
    "ids": [
      "1268719305140600838",
      "1268891249475371013",
      "1377994471149862925",
      "1269670840788017157",
      "1373812125181874177",
      "1269715954264502273",
      "1378568330114633730",
      "1269041884879630339",
      "1374204453801320450",
      "1378190720989851654",
      "1268738019680489472",
      "1269096788289519623",
      "1268725938147262466",
      "1268800774798290944",
      "1268808117543936003",
      "1268723147877912576",
      "1268900597736013825",
      "1268900653654585345",
      "1378749583593984005",
      "1269383836061687810",
      "1269096832224972800",
      "1269293188155609090",
      "1269293231013011456",
      "1269474459074924544",
      "1269474495812812800",
      "1269670789839806465",
      "1374008224349831175",
      "1374385888923320326",
      "1377798328776327171",
      "1378372139032645634",
      "1268719255400390660"
    ]
  },
  "citations": 5,
  "posterSession": "Tuesday"
}