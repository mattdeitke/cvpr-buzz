{
  "arXiv": "http://arxiv.org/abs/2011.14288",
  "title": "Learning Affinity-Aware Upsampling for Deep Image Matting",
  "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Dai_Learning_Affinity-Aware_Upsampling_for_Deep_Image_Matting_CVPR_2021_paper.pdf",
  "authors": [
    "Yutong Dai",
    "Hao Lu",
    "Chunhua Shen"
  ],
  "abstract": "We show that learning affinity in upsampling provides an effective and efficient approach to exploit pairwise interactions in deep networks. Second-order features are commonly used in dense prediction to build adjacent relations with a learnable module after upsampling such as non-local blocks. Since upsampling is essential, learning affinity in upsampling can avoid additional propagation layers, offering the potential for building compact models. By looking at existing upsampling operators from a unified mathematical perspective, we generalize them into a second-order form and introduce Affinity-Aware Upsampling (A2U) where upsampling kernels are generated using a light-weight low-rank bilinear model and are conditioned on second-order features. Our upsampling operator can also be extended to downsampling. We discuss alternative implementations of A2U and verify their effectiveness on two detail-sensitive tasks: image reconstruction on a toy dataset; and a large-scale image matting task where affinity-based ideas constitute mainstream matting approaches. In particular, results on the Composition-1k matting dataset show that A2U achieves a 14% relative improvement in the SAD metric against a strong baseline with negligible increase of parameters (< 0.5%). Compared with the state-of-the-art matting network, we achieve 8% higher performance with only 40% model complexity.",
  "s2id": "865ffe014782a565d70eeb1a362479d22eed6508",
  "citations": 0,
  "posterSession": "Tuesday"
}