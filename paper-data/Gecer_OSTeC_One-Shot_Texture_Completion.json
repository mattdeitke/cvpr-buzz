{
  "arXiv": "http://arxiv.org/abs/2012.15370",
  "title": "OSTeC: One-Shot Texture Completion",
  "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Gecer_OSTeC_One-Shot_Texture_Completion_CVPR_2021_paper.pdf",
  "authors": [
    "Baris Gecer",
    "Jiankang Deng",
    "Stefanos Zafeiriou"
  ],
  "abstract": "The last few years have witnessed the great success of non-linear generative models in synthesizing high-quality photorealistic face images. Many recent 3D facial texture reconstruction and pose manipulation from a single image approaches still rely on large and clean face datasets to train image-to-image Generative Adversarial Networks (GANs). Yet the collection of such a large scale high-resolution 3D texture dataset is still very costly and difficult to maintain age/ethnicity balance. Moreover, regression-based approaches suffer from generalization to the in-the-wild conditions and are unable to fine-tune to a target-image. In this work, we propose an unsupervised approach for one-shot 3D facial texture completion that does not require large-scale texture datasets, but rather harnesses the knowledge stored in 2D face generators. The proposed approach rotates an input image in 3D and fill-in the unseen regions by reconstructing the rotated image in a 2D face generator, based on the visible parts. Finally, we stitch the most visible textures at different angles in the UV image-plane. Further, we frontalize the target image by projecting the completed texture into the generator. The qualitative and quantitative experiments demonstrate that the completed UV textures and frontalized images are of high quality, resembles the original identity, can be used to train a texture GAN model for 3DMM fitting and improve pose-invariant face recognition.",
  "s2id": "9cb2f013ae9137b6dc7c7cb96efdda7569c2af3f",
  "twitter": {
    "retweets": 25,
    "likes": 134,
    "replies": 0
  },
  "citations": 1,
  "posterSession": "Wednesday"
}