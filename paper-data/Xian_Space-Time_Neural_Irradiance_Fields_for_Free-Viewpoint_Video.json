{
  "arXiv": "http://arxiv.org/abs/2011.12950",
  "title": "Space-Time Neural Irradiance Fields for Free-Viewpoint Video",
  "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Xian_Space-Time_Neural_Irradiance_Fields_for_Free-Viewpoint_Video_CVPR_2021_paper.pdf",
  "authors": [
    "Wenqi Xian",
    "Jia-Bin Huang",
    "Johannes Kopf",
    "Changil Kim"
  ],
  "abstract": "We present a method that learns a spatiotemporal neural irradiance field for dynamic scenes from a single video. Our learned representation enables free-viewpoint rendering of the input video. Our method builds upon recent advances in implicit representations. Learning a spatiotemporal irradiance field from a single video poses significant challenges because the video contains only one observation of the scene at any point in time. The 3D geometry of a scene can be legitimately represented in numerous ways since varying geometry (motion) can be explained with varying appearance and vice versa. We address this ambiguity by constraining the time-varying geometry of our dynamic scene representation using the scene depth estimated from video depth estimation methods, aggregating contents from individual frames into a single global representation. We provide an extensive quantitative evaluation and demonstrate compelling free-viewpoint rendering results.",
  "s2id": "15f1da5e77ceac158b84d9c9c4b2016ca1944fe3",
  "twitter": {
    "retweets": 27,
    "likes": 170,
    "replies": 5
  },
  "citations": 27,
  "posterSession": "Wednesday"
}