{
  "arXiv": "http://arxiv.org/abs/2103.02772",
  "title": "DeepTag: An Unsupervised Deep Learning Method for Motion Tracking on Cardiac Tagging Magnetic Resonance Images",
  "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Ye_DeepTag_An_Unsupervised_Deep_Learning_Method_for_Motion_Tracking_on_CVPR_2021_paper.pdf",
  "authors": [
    "Meng Ye",
    "Mikael Kanski",
    "Dong Yang",
    "Qi Chang",
    "Zhennan Yan",
    "Qiaoying Huang",
    "Leon Axel",
    "Dimitris Metaxas"
  ],
  "abstract": "Cardiac tagging magnetic resonance imaging (t-MRI) is the gold standard for regional myocardium deformation and cardiac strain estimation. However, this technique has not been widely used in clinical diagnosis, as a result of the difficulty of motion tracking encountered with t-MRI images. In this paper, we propose a novel deep learning-based fully unsupervised method for in vivo motion tracking on t-MRI images. We first estimate the motion field (INF) between any two consecutive t-MRI frames by a bi-directional generative diffeomorphic registration neural network. Using this result, we then estimate the Lagrangian motion field between the reference frame and any other frame through a differentiable composition layer. By utilizing temporal information to perform reasonable estimations on spatio-temporal motion fields, this novel method provides a useful solution for motion tracking and image registration in dynamic medical imaging. Our method has been validated on a representative clinical t-MRI dataset; the experimental results show that our method is superior to conventional motion tracking methods in terms of landmark tracking accuracy and inference efficiency.",
  "s2id": "581ba7d93349ac0e1eec74385160205bc1accb8a",
  "twitter": {
    "retweets": 8,
    "likes": 12,
    "replies": 0
  },
  "citations": 0,
  "posterSession": "Wednesday"
}