{
  "arXiv": "http://arxiv.org/abs/2102.09105",
  "title": "DeepMetaHandles: Learning Deformation Meta-Handles of 3D Meshes With Biharmonic Coordinates",
  "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Liu_DeepMetaHandles_Learning_Deformation_Meta-Handles_of_3D_Meshes_With_Biharmonic_Coordinates_CVPR_2021_paper.pdf",
  "authors": [
    "Minghua Liu",
    "Minhyuk Sung",
    "Radomir Mech",
    "Hao Su"
  ],
  "abstract": "We propose DeepMetaHandles, a 3D conditional generative model based on mesh deformation. Given a collection of 3D meshes of a category and their deformation handles (control points), our method learns a set of meta-handles for each shape, which are represented as combinations of the given handles. The disentangled meta-handles factorize all the plausible deformations of the shape, while each of them corresponds to an intuitive deformation. A new deformation can then be generated by sampling the coefficients of the meta-handles in a specific range. We employ biharmonic coordinates as the deformation function, which can smoothly propagate the control points' translations to the entire mesh. To avoid learning zero deformation as meta-handles, we incorporate a target-fitting module which deforms the input mesh to match a random target. To enhance deformations' plausibility, we employ a soft-rasterizer-based discriminator that projects the meshes to a 2D space. Our experiments demonstrate the superiority of the generated deformations as well as the interpretability and consistency of the learned meta-handles.",
  "s2id": "14c9fed3842b6116ab2d768e9356630ffa835d85",
  "twitter": {
    "retweets": 0,
    "likes": 2,
    "replies": 0,
    "ids": [
      "1389909374672543744"
    ]
  },
  "citations": 0,
  "posterSession": "Monday"
}