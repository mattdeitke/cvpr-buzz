{
  "arXiv": "http://arxiv.org/abs/2010.11757",
  "title": "Deep Analysis of CNN-Based Spatio-Temporal Representations for Action Recognition",
  "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_Deep_Analysis_of_CNN-Based_Spatio-Temporal_Representations_for_Action_Recognition_CVPR_2021_paper.pdf",
  "authors": [
    "Chun-Fu Richard Chen",
    "Rameswar Panda",
    "Kandan Ramakrishnan",
    "Rogerio Feris",
    "John Cohn",
    "Aude Oliva",
    "Quanfu Fan"
  ],
  "abstract": "In recent years, a number of approaches based on 2D or 3D convolutional neural networks (CNN) have emerged for video action recognition, achieving state-of-the-art results on several large-scale benchmark datasets. In this paper, we carry out in-depth comparative analysis to better understand the differences between these approaches and the progress made by them. To this end, we develop an unified framework for both 2D-CNN and 3D-CNN action models, which enables us to remove bells and whistles and provides a common ground for fair comparison. We then conduct an effort towards a large-scale analysis involving over 300 action recognition models. Our comprehensive analysis reveals that a) a significant leap is made in efficiency for action recognition, but not in accuracy; b) 2D-CNN and 3D-CNN models behave similarly in terms of spatio-temporal representation abilities and transferability. Our codes are available at https://github.com/IBM/action-recognition-pytorch.",
  "s2id": "",
  "twitter": {
    "retweets": 1,
    "likes": 6,
    "replies": 1
  },
  "posterSession": "Tuesday"
}