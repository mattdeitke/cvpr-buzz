{
  "arXiv": "http://arxiv.org/abs/2005.13702",
  "title": "On the Difficulty of Membership Inference Attacks",
  "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Rezaei_On_the_Difficulty_of_Membership_Inference_Attacks_CVPR_2021_paper.pdf",
  "authors": [
    "Shahbaz Rezaei",
    "Xin Liu"
  ],
  "abstract": "Recent studies propose membership inference (MI) attacks on deep models, where the goal is to infer if a sample has been used in the training process. Despite their apparent success, these studies only report accuracy, precision, and recall of the positive class (member class). Hence, the performance of these attacks have not been clearly reported on negative class (non-member class). In this paper, we show that the way the MI attack performance has been reported is often misleading because they suffer from high false positive rate or false alarm rate (FAR) that has not been reported. FAR shows how often the attack model mislabel non-training samples (non-member) as training (member) ones. The high FAR makes MI attacks fundamentally impractical, which is particularly more significant for tasks such as membership inference where the majority of samples in reality belong to the negative (non-training) class. Moreover, we show that the current MI attack models can only identify the membership of misclassified samples with mediocre accuracy at best, which only constitute a very small portion of training samples. We analyze several new features that have not been comprehensively explored for membership inference before, including distance to the decision boundary and gradient norms, and conclude that deep models' responses are mostly similar among train and non-train samples. We conduct several experiments on image classification tasks, including MNIST, CIFAR-10, CIFAR-100, and ImageNet, using various model architecture, including LeNet, AlexNet, ResNet, etc. We show that the current state-of-the-art MI attacks cannot achieve high accuracy and low FAR at the same time, even when the attacker is given several advantages. The source code is available at https://github.com/shrezaei/MI-Attack.",
  "s2id": "",
  "twitter": {
    "retweets": 5,
    "likes": 5,
    "replies": 2,
    "ids": [
      "1271566632981233664",
      "1266187873742544896",
      "1374748200888860680",
      "1266638330780844032",
      "1266182748747837441",
      "1266197704452894721",
      "1266212944813096966",
      "1266263577670807557",
      "1266264148737880064",
      "1266274932448583680",
      "1266394136376197120",
      "1266590214681776140",
      "1266771483579289600",
      "1374566911665655808",
      "1266967764893413376",
      "1267148973233537026",
      "1369115928097677312",
      "1369123240447270915",
      "1369136920706490368",
      "1369312258279550978",
      "1374536775067185155",
      "1374548201550716928",
      "1266181922222485506"
    ]
  },
  "posterSession": "Wednesday"
}