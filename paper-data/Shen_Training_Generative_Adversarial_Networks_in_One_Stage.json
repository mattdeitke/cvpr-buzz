{
  "arXiv": "http://arxiv.org/abs/2103.00430",
  "title": "Training Generative Adversarial Networks in One Stage",
  "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Shen_Training_Generative_Adversarial_Networks_in_One_Stage_CVPR_2021_paper.pdf",
  "authors": [
    "Chengchao Shen",
    "Youtan Yin",
    "Xinchao Wang",
    "Xubin Li",
    "Jie Song",
    "Mingli Song"
  ],
  "abstract": "Generative Adversarial Networks (GANs) have demonstrated unprecedented success in various image generation tasks. The encouraging results, however, come at the price of a cumbersome training process, during which the generator and discriminator are alternately updated in two stages. In this paper, we investigate a general training scheme that enables training GANs efficiently in only one stage. Based on the adversarial losses of the generator and discriminator, we categorize GANs into two classes, Symmetric GANs and Asymmetric GANs, and introduce a novel gradient decomposition method to unify the two, allowing us to train both classes in one stage and hence alleviate the training effort. We also computationally analyze the efficiency of the proposed method, and empirically demonstrate that, the proposed method yields a solid: 1.5x acceleration across various datasets and network architectures. Furthermore, we show that the proposed method is readily applicable to other adversarial-training scenarios, such as data-free knowledge distillation. The code is available at https://github.com/zju-vipa/OSGAN.",
  "s2id": "27ce83180648b63f045d531036055cd6608eebe5",
  "twitter": {
    "retweets": 35,
    "likes": 234,
    "replies": 3
  },
  "citations": 0,
  "posterSession": "Tuesday"
}