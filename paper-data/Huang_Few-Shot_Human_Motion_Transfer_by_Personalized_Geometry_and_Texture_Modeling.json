{
  "arXiv": "http://arxiv.org/abs/2103.14338",
  "title": "Few-Shot Human Motion Transfer by Personalized Geometry and Texture Modeling",
  "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Huang_Few-Shot_Human_Motion_Transfer_by_Personalized_Geometry_and_Texture_Modeling_CVPR_2021_paper.pdf",
  "authors": [
    "Zhichao Huang",
    "Xintong Han",
    "Jia Xu",
    "Tong Zhang"
  ],
  "abstract": "We present a new method for few-shot human motion transfer that achieves realistic human image generation with only a small number of appearance inputs. Despite recent advances in single person motion transfer, prior methods often require a large number of training images and take long training time. One promising direction is to perform few-shot human motion transfer, which only needs a few of source images for appearance transfer. However, it is particularly challenging to obtain satisfactory transfer results. In this paper, we address this issue by rendering a human texture map to a surface geometry (represented as a UV map), which is personalized to the source person. Our geometry generator combines the shape information from source images, and the pose information from 2D keypoints to synthesize the personalized UV map. A texture generator then generates the texture map conditioned on the texture of source images to fill out invisible parts. Furthermore, we may fine-tune the texture map on the manifold of the texture generator from a few source images at the test time, which improves the quality of the texture map without over-fitting or artifacts. Extensive experiments show the proposed method outperforms state-of-the-art methods both qualitatively and quantitatively. Our code is available at https://github.com/HuangZhiChao95/FewShotMotionTransfer.",
  "s2id": "a4551eaa6d9989831b3923957238f60fa51463eb",
  "twitter": {
    "retweets": 9,
    "likes": 45,
    "replies": 0
  },
  "citations": 0
}