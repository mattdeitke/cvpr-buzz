{
  "arXiv": "http://arxiv.org/abs/2101.07889",
  "title": "Joint Learning of 3D Shape Retrieval and Deformation",
  "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Uy_Joint_Learning_of_3D_Shape_Retrieval_and_Deformation_CVPR_2021_paper.pdf",
  "authors": [
    "Mikaela Angelina Uy",
    "Vladimir G. Kim",
    "Minhyuk Sung",
    "Noam Aigerman",
    "Siddhartha Chaudhuri",
    "Leonidas J. Guibas"
  ],
  "abstract": "We propose a novel technique for producing high-quality 3D models that match a given target object image or scan. Our method is based on retrieving an existing shape from a database of 3D models and then deforming its parts to match the target shape. Unlike previous approaches that independently focus on either shape retrieval or deformation, we propose a joint learning procedure that simultaneously trains the neural deformation module along with the embedding space used by the retrieval module. This enables our network to learn a deformation-aware embedding space, so that retrieved models are more amenable to match the target after an appropriate deformation. In fact, we use the embedding space to guide the shape pairs used to train the deformation module, so that it invests its capacity in learning deformations between meaningful shape pairs. Furthermore, our novel part-aware deformation module can work with inconsistent and diverse part-structures on the source shapes. We demonstrate the benefits of our joint training not only on our novel framework, but also on other state-of-the-art neural deformation modules proposed in recent years. Lastly, we also show that our jointly-trained method outperforms various non-joint baselines.",
  "s2id": "8c4e0d0a98676615aeb4e56fa0ab90af618b1afd",
  "twitter": {
    "retweets": 1,
    "likes": 9,
    "replies": 0
  },
  "citations": 2,
  "posterSession": "Thursday"
}