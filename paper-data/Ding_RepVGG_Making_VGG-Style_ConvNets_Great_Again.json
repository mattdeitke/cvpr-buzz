{
  "arXiv": "http://arxiv.org/abs/2101.03697",
  "title": "RepVGG: Making VGG-Style ConvNets Great Again",
  "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Ding_RepVGG_Making_VGG-Style_ConvNets_Great_Again_CVPR_2021_paper.pdf",
  "authors": [
    "Xiaohan Ding",
    "Xiangyu Zhang",
    "Ningning Ma",
    "Jungong Han",
    "Guiguang Ding",
    "Jian Sun"
  ],
  "abstract": "We present a simple but powerful architecture of convolutional neural network, which has a VGG-like inference-time body composed of nothing but a stack of 3x3 convolution and ReLU, while the training-time model has a multi-branch topology. Such decoupling of the training-time and inference-time architecture is realized by a structural re-parameterization technique so that the model is named RepVGG. On ImageNet, RepVGG reaches over 80% top-1 accuracy, which is the first time for a plain model, to the best of our knowledge. On NVIDIA 1080Ti GPU, RepVGG models run 83% faster than ResNet-50 or 101% faster than ResNet-101 with higher accuracy and show favorable accuracy-speed trade-off compared to the state-of-the-art models like EfficientNet and RegNet. The code and trained models are available at https://github.com/megvii-model/RepVGG.",
  "s2id": "2b8088253e2378fce001a090fe923b81e8dedf25",
  "twitter": {
    "retweets": 319,
    "likes": 1558,
    "replies": 15
  },
  "citations": 7
}