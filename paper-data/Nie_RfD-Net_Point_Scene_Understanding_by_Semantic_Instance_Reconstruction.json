{
  "arXiv": null,
  "title": "RfD-Net: Point Scene Understanding by Semantic Instance Reconstruction",
  "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Nie_RfD-Net_Point_Scene_Understanding_by_Semantic_Instance_Reconstruction_CVPR_2021_paper.pdf",
  "authors": [
    "Yinyu Nie",
    "Ji Hou",
    "Xiaoguang Han",
    "Matthias Niessner"
  ],
  "abstract": "Semantic scene understanding from point clouds is particularly challenging as the points reflect only a sparse set of the underlying 3D geometry. Previous works often convert point cloud into regular grids (e.g. voxels or bird-eye view images), and resort to grid-based convolutions for scene understanding. In this work, we introduce RfD-Net that jointly detects and reconstructs dense object surfaces directly from raw point clouds. Instead of representing scenes with regular grids, our method leverages the sparsity of point cloud data and focuses on predicting shapes that are recognized with high objectness. With this design, we decouple the instance reconstruction into global object localization and local shape prediction. It not only eases the difficulty of learning 2-D manifold surfaces from sparse 3D space, the point clouds in each object proposal convey shape details that support implicit function learning to reconstruct any high-resolution surfaces. Our experiments indicate that instance detection and reconstruction present complementary effects, where the shape prediction head shows consistent effects on improving object detection with modern 3D proposal network backbones. The qualitative and quantitative evaluations further demonstrate that our approach consistently outperforms the state-of-the-arts and improves over 11 of mesh IoU in object reconstruction.",
  "s2id": "d5a11c9ce83b6b79172d724cf2ca77a8c415bdba",
  "twitter": {
    "retweets": 10,
    "likes": 34,
    "replies": 0
  },
  "citations": 2,
  "posterSession": "Tuesday"
}