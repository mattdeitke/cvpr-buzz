{
  "arXiv": null,
  "title": "Mining Better Samples for Contrastive Learning of Temporal Correspondence",
  "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Jeon_Mining_Better_Samples_for_Contrastive_Learning_of_Temporal_Correspondence_CVPR_2021_paper.pdf",
  "authors": [
    "Sangryul Jeon",
    "Dongbo Min",
    "Seungryong Kim",
    "Kwanghoon Sohn"
  ],
  "abstract": "We present a novel framework for contrastive learning of pixel-level representation using only unlabeled video. Without the need of ground-truth annotation, our method is capable of collecting well-defined positive correspondences by measuring their confidences and well-defined negative ones by appropriately adjusting their hardness during training. This allows us to suppress the adverse impact of ambiguous matches and prevent a trivial solution from being yielded by too hard or too easy negative samples. To accomplish this, we incorporate three different criteria that ranges from a pixel-level matching confidence to a video-level one into a bottom-up pipeline, and plan a curriculum that is aware of current representation power for the adaptive hardness of negative samples during training. With the proposed method, state-of-the-art performance is attained over the latest approaches on several video label propagation tasks.",
  "s2id": "",
  "posterSession": "Monday"
}