{
  "arXiv": "http://arxiv.org/abs/2011.11498",
  "title": "HoHoNet: 360 Indoor Holistic Understanding With Latent Horizontal Features",
  "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Sun_HoHoNet_360_Indoor_Holistic_Understanding_With_Latent_Horizontal_Features_CVPR_2021_paper.pdf",
  "authors": [
    "Cheng Sun",
    "Min Sun",
    "Hwann-Tzong Chen"
  ],
  "abstract": "We present HoHoNet, a versatile and efficient framework for holistic understanding of an indoor 360-degree panorama using a Latent Horizontal Feature (LHFeat). The compact LHFeat flattens the features along the vertical direction and has shown success in modeling per-column modality for room layout reconstruction. HoHoNet advances in two important aspects. First, the deep architecture is redesigned to run faster with improved accuracy. Second, we propose a novel horizon-to-dense module, which relaxes the per-column output shape constraint, allowing per-pixel dense prediction from LHFeat. HoHoNet is fast: It runs at 52 FPS and 110 FPS with ResNet-50 and ResNet-34 backbones respectively, for modeling dense modalities from a high-resolution 512x1024 panorama. HoHoNet is also accurate. On the tasks of layout estimation and semantic segmentation, HoHoNet achieves results on par with current state-of-the-art. On dense depth estimation, HoHoNet outperforms all the prior arts by a large margin.",
  "s2id": "335637b2a3facaee05bda38c9c5af50e4a4ecfed",
  "twitter": {
    "retweets": 0,
    "likes": 2,
    "replies": 0
  },
  "citations": 1
}