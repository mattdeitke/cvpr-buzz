{
  "arXiv": "http://arxiv.org/abs/2011.13377",
  "title": "How Well Do Self-Supervised Models Transfer?",
  "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Ericsson_How_Well_Do_Self-Supervised_Models_Transfer_CVPR_2021_paper.pdf",
  "authors": [
    "Linus Ericsson",
    "Henry Gouk",
    "Timothy M. Hospedales"
  ],
  "abstract": "Self-supervised visual representation learning has seen huge progress recently, but no large scale evaluation has compared the many models now available. We evaluate the transfer performance of 13 top self-supervised models on 40 downstream tasks, including many-shot and few-shot recognition, object detection, and dense prediction. We compare their performance to a supervised baseline and show that on most tasks the best self-supervised models outperform supervision, confirming the recently observed trend in the literature. We find ImageNet Top-1 accuracy to be highly correlated with transfer to many-shot recognition, but increasingly less so for few-shot, object detection and dense prediction. No single self-supervised method dominates overall, suggesting that universal pre-training is still unsolved. Our analysis of features suggests that top self-supervised learners fail to preserve colour information as well as supervised alternatives, but tend to induce better classifier calibration, and less attentive overfitting than supervised learners.",
  "s2id": "00969b4dcf8f9b21895bd038a51a038018da84f0",
  "twitter": {
    "retweets": 4,
    "likes": 29,
    "replies": 1,
    "ids": [
      "1333297030945333249",
      "1390421316700835845",
      "1333420852575162368",
      "1333239632629297153"
    ]
  },
  "citations": 7,
  "posterSession": "Tuesday"
}