{
  "arXiv": "http://arxiv.org/abs/2003.11883",
  "title": "DCNAS: Densely Connected Neural Architecture Search for Semantic Image Segmentation",
  "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhang_DCNAS_Densely_Connected_Neural_Architecture_Search_for_Semantic_Image_Segmentation_CVPR_2021_paper.pdf",
  "authors": [
    "Xiong Zhang",
    "Hongmin Xu",
    "Hong Mo",
    "Jianchao Tan",
    "Cheng Yang",
    "Lei Wang",
    "Wenqi Ren"
  ],
  "abstract": "Existing NAS methods for dense image prediction tasks usually compromise on restricted search space or search on proxy task to meet the achievable computational demands. To allow as wide as possible network architectures and avoid the gap between realistic and proxy setting, we propose a novel Densely Connected NAS (DCNAS) framework, which directly searches the optimal network structures for the multi-scale representations of visual information, over a large-scale target dataset without proxy. Specifically, by connecting cells with each other using learnable weights, we introduce a densely connected search space to cover an abundance of mainstream network designs. Moreover, by combining both path-level and channel-level sampling strategies, we design a fusion module and mixture layer to reduce the memory consumption of ample search space, hence favoring the proxyless searching. Compared with contemporary works, experiments reveal that the proxyless searching scheme is capable of bridging the gap between searching and training environments. Further, DCNAS achieves new state-of-the-art performances on public semantic image segmentation benchmarks, including 84.3% on Cityscapes, and 86.9% on PASCAL VOC 2012. We also retain leading performances when evaluating the architecture on the more challenging ADE20K and PASCAL-Context dataset.",
  "s2id": "0592b3df99b9fd032e7adf94727a58aaf66bef38",
  "twitter": {
    "retweets": 3,
    "likes": 4,
    "replies": 3
  },
  "citations": 6
}