{
  "arXiv": "http://arxiv.org/abs/2104.01845",
  "title": "Unsupervised Multi-Source Domain Adaptation Without Access to Source Data",
  "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Ahmed_Unsupervised_Multi-Source_Domain_Adaptation_Without_Access_to_Source_Data_CVPR_2021_paper.pdf",
  "authors": [
    "Sk Miraj Ahmed",
    "Dripta S. Raychaudhuri",
    "Sujoy Paul",
    "Samet Oymak",
    "Amit K. Roy-Chowdhury"
  ],
  "abstract": "Unsupervised Domain Adaptation (UDA) aims to learn a predictor model for an unlabeled dataset by transferring knowledge from a labeled source data, which has been trained on similar tasks. However, most of these conventional UDA approaches have a strong assumption of having access to the source data during training, which may not be very practical due to privacy, security and storage concerns. A recent line of work addressed this problem and proposed an algorithm that transfers knowledge to the unlabeled target domain only from a single learned source model without requiring access to the source data. However, for adaptation purpose, if there are multiple trained source models available to choose from, this method has to go through adapting each and every model individually, to check for the best source. Thus, we ask the question: can we find the optimal combination of source models, with no source data and without target labels, whose performance is no worse than the single best source? To answer this, we propose a novel and efficient algorithm which automatically combines the source models with suitable weights in such a way that it performs at least as good as the best source model. We provide intuitive theoretical insights to justify our claim. Moreover, extensive experiments are conducted on several benchmark datasets to show the effectiveness of our algorithm, where in most cases, our method not only reaches best source accuracy but also outperform it.",
  "s2id": "775a1a2eadac7fd672551aae78af2eb7a4d234ae",
  "citations": 1,
  "posterSession": "Wednesday"
}