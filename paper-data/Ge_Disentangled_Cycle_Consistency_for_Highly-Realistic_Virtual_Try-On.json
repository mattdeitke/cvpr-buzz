{
  "arXiv": "http://arxiv.org/abs/2103.09479",
  "title": "Disentangled Cycle Consistency for Highly-Realistic Virtual Try-On",
  "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Ge_Disentangled_Cycle_Consistency_for_Highly-Realistic_Virtual_Try-On_CVPR_2021_paper.pdf",
  "authors": [
    "Chongjian Ge",
    "Yibing Song",
    "Yuying Ge",
    "Han Yang",
    "Wei Liu",
    "Ping Luo"
  ],
  "abstract": "Image virtual try-on replaces the clothes on a person image with a desired in-shop clothes image. It is challenging because the person and the in-shop clothes are unpaired. Existing methods formulate virtual try-on as either in-painting or cycle consistency. Both of these two formulations encourage the generation networks to reconstruct the input image in a self-supervised manner. However, existing methods do not differentiate clothing and non-clothing regions. A straightforward generation impedes the virtual try-on quality because of the heavily coupled image contents. In this paper, we propose a Disentangled Cycle-consistency Try-On Network (DCTON). The DCTON is able to produce highly-realistic try-on images by disentangling important components of virtual try-on including clothes warping, skin synthesis, and image composition. Moreover, DCTON can be naturally trained in a self-supervised manner following cycle consistency learning. Extensive experiments on challenging benchmarks show that DCTON outperforms state-of-the-art approaches favorably.",
  "s2id": "c6134edae495482f82c3c5137892ce424d3bd9e4",
  "twitter": {
    "retweets": 0,
    "likes": 9,
    "replies": 3
  },
  "citations": 0,
  "posterSession": "Friday"
}