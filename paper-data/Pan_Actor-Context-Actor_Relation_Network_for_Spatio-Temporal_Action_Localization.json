{
  "arXiv": "http://arxiv.org/abs/2006.07976",
  "title": "Actor-Context-Actor Relation Network for Spatio-Temporal Action Localization",
  "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Pan_Actor-Context-Actor_Relation_Network_for_Spatio-Temporal_Action_Localization_CVPR_2021_paper.pdf",
  "authors": [
    "Junting Pan",
    "Siyu Chen",
    "Mike Zheng Shou",
    "Yu Liu",
    "Jing Shao",
    "Hongsheng Li"
  ],
  "abstract": "Localizing persons and recognizing their actions from videos is a challenging task towards high-level video under-standing. Recent advances have been achieved by modeling direct pairwise relations between entities. In this paper, we take one step further, not only model direct relations between pairs but also take into account indirect higher-order relations established upon multiple elements. We propose to explicitly model the Actor-Context-Actor Relation, which is the relation between two actors based on their interactions with the context. To this end, we design an Actor-Context-Actor Relation Network (ACAR-Net) which builds upon a novel High-order Relation Reasoning Operator and an Actor-Context Feature Bank to enable indirect relation reasoning for spatio-temporal action localization. Experiments on AVA and UCF101-24 datasets show the advantages of modeling actor-context-actor relations, and visualization of attention maps further verifies that our model is capable of finding relevant higher-order relations to support action detection. Notably, our method ranks first in the AVA-Kinetics action localization task of ActivityNet Challenge 2020, outperforming other entries by a significant margin (+6.71 mAP). The code is available online.",
  "s2id": "12a1598a2861c647f0551454f8cbb2b1d55917b8",
  "twitter": {
    "retweets": 2,
    "likes": 11,
    "replies": 1
  },
  "citations": 3,
  "posterSession": "Monday"
}