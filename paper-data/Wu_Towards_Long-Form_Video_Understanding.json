{
  "arXiv": null,
  "title": "Towards Long-Form Video Understanding",
  "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wu_Towards_Long-Form_Video_Understanding_CVPR_2021_paper.pdf",
  "authors": [
    "Chao-Yuan Wu",
    "Philipp Krahenbuhl"
  ],
  "abstract": "Our world offers a never-ending stream of visual stimuli, yet today's vision systems only accurately recognize patterns within a few seconds. These systems understand the present, but fail to contextualize it in past or future events. In this paper, we study long-form video understanding. We introduce a framework for modeling long-form videos and develop evaluation protocols on large-scale datasets. We show that existing state-of-the-art short-term models are limited for long-form tasks. A novel object-centric transformer-based video recognition architecture performs significantly better on 7 diverse tasks. It also outperforms comparable state-of-the-art on the AVA dataset.",
  "s2id": "",
  "posterSession": "Monday"
}