{
  "arXiv": "http://arxiv.org/abs/2105.01839",
  "title": "Encoder Fusion Network With Co-Attention Embedding for Referring Image Segmentation",
  "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Feng_Encoder_Fusion_Network_With_Co-Attention_Embedding_for_Referring_Image_Segmentation_CVPR_2021_paper.pdf",
  "authors": [
    "Guang Feng",
    "Zhiwei Hu",
    "Lihe Zhang",
    "Huchuan Lu"
  ],
  "abstract": "Recently, referring image segmentation has aroused widespread interest. Previous methods perform the multi-modal fusion between language and vision at the decoding side of the network. And, linguistic feature interacts with visual feature of each scale separately, which ignores the continuous guidance of language to multi-scale visual features. In this work, we propose an encoder fusion network (EFN), which transforms the visual encoder into a multi-modal feature learning network, and uses language to refine the multi-modal features progressively. Moreover, a co-attention mechanism is embedded in the EFN to realize the parallel update of multi-modal features, which can promote the consistent of the cross-modal information representation in the semantic space. Finally, we propose a boundary enhancement module (BEM) to make the network pay more attention to the fine structure. The experiment results on four benchmark datasets demonstrate that the proposed approach achieves the state-of-the-art performance under different evaluation metrics without any post-processing.",
  "s2id": "102cbf1eb78b2c0bdb998ac514dcbae27143c85a",
  "twitter": {
    "retweets": 0,
    "likes": 6,
    "replies": 0
  },
  "citations": 0
}