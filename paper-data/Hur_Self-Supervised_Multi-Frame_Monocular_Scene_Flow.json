{
  "arXiv": "http://arxiv.org/abs/2105.02216",
  "title": "Self-Supervised Multi-Frame Monocular Scene Flow",
  "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Hur_Self-Supervised_Multi-Frame_Monocular_Scene_Flow_CVPR_2021_paper.pdf",
  "authors": [
    "Junhwa Hur",
    "Stefan Roth"
  ],
  "abstract": "Estimating 3D scene flow from a sequence of monocular images has been gaining increased attention due to the simple, economical capture setup. Owing to the severe ill-posedness of the problem, the accuracy of current methods has been limited, especially that of efficient, real-time approaches. In this paper, we introduce a multi-frame monocular scene flow network based on self-supervised learning, improving the accuracy over previous networks while retaining real-time efficiency. Based on an advanced two-frame baseline with a split-decoder design, we propose (i) a multi-frame model using a triple frame input and convolutional LSTM connections, (ii) an occlusion-aware census loss for better accuracy, and (iii) a gradient detaching strategy to improve training stability. On the KITTI dataset, we observe state-of-the-art accuracy among monocular scene flow methods based on self-supervised learning.",
  "s2id": "4372af4b7be18f92d7269eba8d5c802de272c964",
  "twitter": {
    "retweets": 15,
    "likes": 107,
    "replies": 1
  },
  "citations": 0
}