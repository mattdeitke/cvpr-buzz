{
  "arXiv": "http://arxiv.org/abs/2103.07700",
  "title": "NeuralHumanFVV: Real-Time Neural Volumetric Human Performance Rendering Using RGB Cameras",
  "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Suo_NeuralHumanFVV_Real-Time_Neural_Volumetric_Human_Performance_Rendering_Using_RGB_Cameras_CVPR_2021_paper.pdf",
  "authors": [
    "Xin Suo",
    "Yuheng Jiang",
    "Pei Lin",
    "Yingliang Zhang",
    "Minye Wu",
    "Kaiwen Guo",
    "Lan Xu"
  ],
  "abstract": "4D reconstruction and rendering of human activities is critical for immersive VR/AR experience. Recent advances still fail to recover fine geometry and texture results with the level of detail present in the input images from sparse multi-view RGB cameras. In this paper, we propose NeuralHumanFVV, a real-time neural human performance capture and rendering system to generate both high-quality geometry and photo-realistic texture of human activities in arbitrary novel views. We propose a neural geometry generation scheme with a hierarchical sampling strategy for real-time implicit geometry inference, as well as a novel neural blending scheme to generate high resolution (e.g., 1k) and photo-realistic texture results in the novel views. Furthermore, we adopt neural normal blending to enhance geometry details and formulate our neural geometry and texture rendering into a multi-task learning framework. Extensive experiments demonstrate the effectiveness of our approach to achieve high-quality geometry and photo-realistic free view-point reconstruction for challenging human performances.",
  "s2id": "fbe34c9add92077f1ea0dc2d3cad1ab95c49f7d5",
  "twitter": {
    "retweets": 0,
    "likes": 0,
    "replies": 1,
    "ids": [
      "1373128557002637315"
    ]
  },
  "citations": 2,
  "posterSession": "Tuesday"
}