{
  "arXiv": null,
  "title": "Kaleido-BERT: Vision-Language Pre-Training on Fashion Domain",
  "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhuge_Kaleido-BERT_Vision-Language_Pre-Training_on_Fashion_Domain_CVPR_2021_paper.pdf",
  "authors": [
    "Mingchen Zhuge",
    "Dehong Gao",
    "Deng-Ping Fan",
    "Linbo Jin",
    "Ben Chen",
    "Haoming Zhou",
    "Minghui Qiu",
    "Ling Shao"
  ],
  "abstract": "We present a new vision-language (VL) pre-training model dubbed Kaleido-BERT, which introduces a novel kaleido strategy for fashion cross-modality representations from transformers. In contrast to random masking strategy of recent VL models, we design alignment guided masking to jointly focus more on image-text semantic relations. To this end, we carry out five novel tasks, i.e., rotation, jigsaw, camouflage, grey-to-color, and blank-to-color for self-supervised VL pre-training at patches of different scale. Kaleido-BERT is conceptually simple and easy to extend to the existing BERT framework, it attains new state-of-the-art results by large margins on four downstream tasks, including text retrieval (R@1: 4.03% absolute improvement), image retrieval (R@1: 7.13% abs imv.), category recognition (ACC: 3.28% abs imv.), and fashion captioning (Bleu4: 1.2 abs imv.). We validate the efficiency of Kaleido-BERT on a wide range of e-commerical websites, demonstrating its broader potential in real-world applications.",
  "s2id": "809b231e915c35db47cb81abfd8600f4c0f9fa10",
  "twitter": {
    "retweets": 5,
    "likes": 31,
    "replies": 2
  },
  "citations": 1
}