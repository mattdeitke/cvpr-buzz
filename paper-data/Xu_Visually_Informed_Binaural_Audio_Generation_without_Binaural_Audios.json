{
  "arXiv": "http://arxiv.org/abs/2104.06162",
  "title": "Visually Informed Binaural Audio Generation without Binaural Audios",
  "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Xu_Visually_Informed_Binaural_Audio_Generation_without_Binaural_Audios_CVPR_2021_paper.pdf",
  "authors": [
    "Xudong Xu",
    "Hang Zhou",
    "Ziwei Liu",
    "Bo Dai",
    "Xiaogang Wang",
    "Dahua Lin"
  ],
  "abstract": "Stereophonic audio, especially binaural audio, plays an essential role in immersive viewing environments. Recent research has explored generating stereophonic audios guided by visual cues and multi-channel audio collections in a fully-supervised manner. However, due to the requirement of professional recording devices, existing datasets are limited in scale and variety, which impedes the generalization of supervised methods to real-world scenarios. In this work, we propose PseudoBinaural, an effective pipeline that is free of binaural recordings. The key insight is to carefully build pseudo visual-stereo pairs with mono data for training. Specifically, we leverage spherical harmonic decomposition and head-related impulse response (HRIR) to identify the relationship between the location of a sound source and the received binaural audio. Then in the visual modality, corresponding visual cues of the mono data are manually placed at sound source positions to form the pairs. Compared to fully-supervised paradigms, our binaural-recording-free pipeline shows great stability in the cross-dataset evaluation and comparable performance under subjective preference. Moreover, combined with binaural recorded data, our method is able to further boost the performance of binaural audio generation under supervised settings.",
  "s2id": "06a48439d4eab9d73f440c1db57fa67bf023f030",
  "twitter": {
    "retweets": 3,
    "likes": 18,
    "replies": 1
  },
  "citations": 4,
  "posterSession": "Thursday"
}