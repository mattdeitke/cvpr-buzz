{
  "arXiv": "http://arxiv.org/abs/2012.01411",
  "title": "PatchmatchNet: Learned Multi-View Patchmatch Stereo",
  "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_PatchmatchNet_Learned_Multi-View_Patchmatch_Stereo_CVPR_2021_paper.pdf",
  "authors": [
    "Fangjinhua Wang",
    "Silvano Galliani",
    "Christoph Vogel",
    "Pablo Speciale",
    "Marc Pollefeys"
  ],
  "abstract": "We present PatchmatchNet, a novel and learnable cascade formulation of Patchmatch for high-resolution multi-view stereo. With high computation speed and low memory requirement, PatchmatchNet can process higher resolution imagery and is more suited to run on resource limited devices than competitors that employ 3D cost volume regularization. For the first time we introduce an iterative multi-scale Patchmatch in an end-to-end trainable architecture and improve the Patchmatch core algorithm with a novel and learned adaptive propagation and evaluation scheme for each iteration. Extensive experiments show a very competitive performance and generalization for our method on DTU, Tanks & Temples and ETH3D, but at a significantly higher efficiency than all existing top-performing models: at least two and a half times faster than state-of-the-art methods with twice less memory usage. Code is available at https://github.com/FangjinhuaWang/PatchmatchNet.",
  "s2id": "b9ec0bb70a2425493f187ccaf8ea0461e90a7381",
  "twitter": {
    "retweets": 2,
    "likes": 32,
    "replies": 3
  },
  "citations": 0
}