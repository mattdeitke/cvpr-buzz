{
  "arXiv": "http://arxiv.org/abs/2103.06818",
  "title": "Coming Down to Earth: Satellite-to-Street View Synthesis for Geo-Localization",
  "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Toker_Coming_Down_to_Earth_Satellite-to-Street_View_Synthesis_for_Geo-Localization_CVPR_2021_paper.pdf",
  "authors": [
    "Aysim Toker",
    "Qunjie Zhou",
    "Maxim Maximov",
    "Laura Leal-Taixe"
  ],
  "abstract": "The goal of cross-view image based geo-localization is to determine the location of a given street view image by matching it against a collection of geo-tagged satellite images. This task is notoriously challenging due to the drastic viewpoint and appearance differences between the two domains. We show that we can address this discrepancy explicitly by learning to synthesize realistic street views from satellite inputs. Following this observation, we propose a novel multi-task architecture in which image synthesis and retrieval are considered jointly. The rationale behind this is that we can bias our network to learn latent feature representations that are useful for retrieval if we utilize them to generate images across the two input domains. To the best of our knowledge, ours is the first approach that creates realistic street views from satellite images and localizes the corresponding query street view simultaneously in an end-to-end manner. In our experiments, we obtain state-of-the-art performance on the CVUSA and CVACT benchmarks. Finally, we show compelling qualitative results for satellite-to-street view synthesis.",
  "s2id": "63cc6611b06d57e5e8e3a8a22d62697b23737888",
  "twitter": {
    "retweets": 0,
    "likes": 0,
    "replies": 1
  },
  "citations": 0,
  "posterSession": "Tuesday"
}