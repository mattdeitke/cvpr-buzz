{
  "arXiv": null,
  "title": "PVGNet: A Bottom-Up One-Stage 3D Object Detector With Integrated Multi-Level Features",
  "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Miao_PVGNet_A_Bottom-Up_One-Stage_3D_Object_Detector_With_Integrated_Multi-Level_CVPR_2021_paper.pdf",
  "authors": [
    "Zhenwei Miao",
    "Jikai Chen",
    "Hongyu Pan",
    "Ruiwen Zhang",
    "Kaixuan Liu",
    "Peihan Hao",
    "Jun Zhu",
    "Yang Wang",
    "Xin Zhan"
  ],
  "abstract": "Quantization-based methods are widely used in LiDAR points 3D object detection for its efficiency in extracting context information. Unlike image where the context information is distributed evenly over the object, most LiDAR points are distributed along the object boundary, which means the boundary features are more critical in LiDAR points 3D detection. However, quantization inevitably introduces ambiguity during both the training and inference stages. To alleviate this problem, we propose a one-stage and voting-based 3D detector, named Point-Voxel-Grid Network (PVGNet). In particular, PVGNet extracts point, voxel and grid-level features in a unified backbone architecture and produces point-wise fusion features. It segments LiDAR points into foreground and background, predicts a 3D bounding box for each foreground point, and performs group voting to get the final detection results. Moreover, we observe that instance-level point imbalance due to occlusion and observation distance also degrades the detection performance. A novel instance-aware focal loss is proposed to alleviate this problem and further improve the detection ability. We conduct experiments on the KITTI and Waymo datasets. Our proposed PVGNet outperforms previous state-of-the-art methods and ranks at the top of KITTI 3D/BEV detection leaderboards.",
  "s2id": "",
  "posterSession": "Tuesday"
}