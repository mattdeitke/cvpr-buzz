{
  "arXiv": "http://arxiv.org/abs/2103.10095",
  "title": "On Semantic Similarity in Video Retrieval",
  "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wray_On_Semantic_Similarity_in_Video_Retrieval_CVPR_2021_paper.pdf",
  "authors": [
    "Michael Wray",
    "Hazel Doughty",
    "Dima Damen"
  ],
  "abstract": "Current video retrieval efforts all found their evaluation on an instance-based assumption, that only a single caption is relevant to a query video and vice versa. We demonstrate that this assumption results in performance comparisons often not indicative of models' retrieval capabilities. We propose a move to semantic similarity video retrieval, where (i) multiple videos/captions can be deemed equally relevant, and their relative ranking does not affect a method's reported performance and (ii) retrieved videos/captions are ranked by their similarity to a query. We propose several proxies to estimate semantic similarities in large-scale retrieval datasets, without additional annotations. Our analysis is performed on three commonly used video retrieval datasets (MSR-VTT, YouCook2 and EPIC-KITCHENS).",
  "s2id": "c5ec16be37131398704bab98b71a154028733731",
  "twitter": {
    "retweets": 21,
    "likes": 120,
    "replies": 3,
    "ids": [
      "1372907428493283336",
      "1372917884817670147",
      "1372719289791303682",
      "1372769907255902209",
      "1373147470146924544",
      "1373660856312078337",
      "1373464751142014979",
      "1373283499730477058",
      "1373126504205283329",
      "1373102087345741828",
      "1372905960356843523",
      "1372755025676488705",
      "1372724764318523394"
    ]
  },
  "citations": 0,
  "posterSession": "Tuesday"
}