{
  "arXiv": "http://arxiv.org/abs/2104.02366",
  "title": "Neural Feature Search for RGB-Infrared Person Re-Identification",
  "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chen_Neural_Feature_Search_for_RGB-Infrared_Person_Re-Identification_CVPR_2021_paper.pdf",
  "authors": [
    "Yehansen Chen",
    "Lin Wan",
    "Zhihang Li",
    "Qianyan Jing",
    "Zongyuan Sun"
  ],
  "abstract": "RGB-Infrared person re-identification (RGB-IR ReID) is a challenging cross-modality retrieval problem, which aims at matching the person-of-interest over visible and infrared camera views. Most existing works achieve performance gains through manually-designed feature selection modules, which often require significant domain knowledge and rich experience. In this paper, we study a general paradigm, termed Neural Feature Search (NFS), to automate the process of feature selection. Specifically, NFS combines a dual-level feature search space and a differentiable search strategy to jointly select identity-related cues in coarse-grained channels and fine-grained spatial pixels. This combination allows NFS to adaptively filter background noises and concentrate on informative parts of human bodies in a data-driven manner. Moreover, a cross-modality contrastive optimization scheme further guides NFS to search features that can minimize modality discrepancy whilst maximizing inter-class distance. Extensive experiments on mainstream benchmarks demonstrate that our method outperforms state-of-the-arts, especially achieving better performance on the RegDB dataset with significant improvement of 11.20% and 8.64% in Rank-1 and mAP, respectively.",
  "s2id": "bd807fdada8eb0d5e003b237338c3100acfc409b",
  "citations": 0
}