{
  "arXiv": null,
  "title": "Deep RGB-D Saliency Detection With Depth-Sensitive Attention and Automatic Multi-Modal Fusion",
  "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Sun_Deep_RGB-D_Saliency_Detection_With_Depth-Sensitive_Attention_and_Automatic_Multi-Modal_CVPR_2021_paper.pdf",
  "authors": [
    "Peng Sun",
    "Wenhu Zhang",
    "Huanyu Wang",
    "Songyuan Li",
    "Xi Li"
  ],
  "abstract": "RGB-D salient object detection (SOD) is usually formulated as a problem of classification or regression over two modalities, i.e., RGB and depth. Hence, effective RGB-D feature modeling and multi-modal feature fusion both play a vital role in RGB-D SOD. In this paper, we propose a depth-sensitive RGB feature modeling scheme using the depth-wise geometric prior of salient objects. In principle, the feature modeling scheme is carried out in a depth-sensitive attention module, which leads to the RGB feature enhancement as well as the background distraction reduction by capturing the depth geometry prior. Moreover, to perform effective multi-modal feature fusion, we further present an automatic architecture search approach for RGB-D SOD, which does well in finding out a feasible architecture from our specially designed multi-modal multi-scale search space. Extensive experiments on seven standard benchmarks demonstrate the effectiveness of the proposed approach against the state-of-the-art.",
  "s2id": "a83a62da1564721cc41b8ae037ba17563c233955",
  "citations": 0
}