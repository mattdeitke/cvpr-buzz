{
  "arXiv": "http://arxiv.org/abs/2103.08468",
  "title": "Beyond Image to Depth: Improving Depth Prediction Using Echoes",
  "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Parida_Beyond_Image_to_Depth_Improving_Depth_Prediction_Using_Echoes_CVPR_2021_paper.pdf",
  "authors": [
    "Kranti Kumar Parida",
    "Siddharth Srivastava",
    "Gaurav Sharma"
  ],
  "abstract": "We address the problem of estimating depth with multi modal audio visual data. Inspired by the ability of animals, such as bats and dolphins, to infer distance of objects with echolocation, some recent methods have utilized echoes for depth estimation. We propose an end-to-end deep learning based pipeline utilizing RGB images, binaural echoes and estimated material properties of various objects within a scene. We argue that the relation between image, echoes and depth, for different scene elements, is greatly influenced by the properties of those elements, and a method designed to leverage this information can lead to significantly improved depth estimation from audio visual inputs. We propose a novel multi modal fusion technique, which incorporates the material properties explicitly while combining audio (echoes) and visual modalities to predict the scene depth. We show empirically, with experiments on Replica dataset, that the proposed method obtains 28% improvement in RMSE compared to the state-of-the-art audio-visual depth prediction method. To demonstrate the effectiveness of our method on larger dataset, we report competitive performance on Matterport3D, proposing to use it as a multi modal depth prediction benchmark with echoes for the first time. We also analyse the proposed method with exhaustive ablation experiments and qualitative results.",
  "s2id": "04d70c5e2f16b7825c1247938d339e325725c270",
  "twitter": {
    "retweets": 0,
    "likes": 11,
    "replies": 2
  },
  "citations": 1
}