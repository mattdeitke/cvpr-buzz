{
  "arXiv": "http://arxiv.org/abs/2103.16651",
  "title": "DAP: Detection-Aware Pre-Training With Weak Supervision",
  "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhong_DAP_Detection-Aware_Pre-Training_With_Weak_Supervision_CVPR_2021_paper.pdf",
  "authors": [
    "Yuanyi Zhong",
    "Jianfeng Wang",
    "Lijuan Wang",
    "Jian Peng",
    "Yu-Xiong Wang",
    "Lei Zhang"
  ],
  "abstract": "This paper presents a detection-aware pre-training (DAP) approach, which leverages only weakly-labeled classification-style datasets (e.g., ImageNet) for pre-training, but is specifically tailored to benefit object detection tasks. In contrast to the widely used image classification-based pre-training (e.g., on ImageNet), which does not include any location-related training tasks, we transform a classification dataset into a detection dataset through a weakly supervised object localization method based on Class Activation Maps to directly pre-train a detector, making the pre-trained model location-aware and capable of predicting bounding boxes. We show that DAP can outperform the traditional classification pre-training in terms of both sample efficiency and convergence speed in downstream detection tasks including VOC and COCO. In particular, DAP boosts the detection accuracy by a large margin when the number of examples in the downstream task is small.",
  "s2id": "3c6321c030b656f6735c0b0239a18b7f8d30f438",
  "citations": 0
}