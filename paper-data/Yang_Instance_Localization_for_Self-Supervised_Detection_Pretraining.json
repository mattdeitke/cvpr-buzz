{
  "arXiv": "http://arxiv.org/abs/2102.08318",
  "title": "Instance Localization for Self-Supervised Detection Pretraining",
  "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yang_Instance_Localization_for_Self-Supervised_Detection_Pretraining_CVPR_2021_paper.pdf",
  "authors": [
    "Ceyuan Yang",
    "Zhirong Wu",
    "Bolei Zhou",
    "Stephen Lin"
  ],
  "abstract": "Prior research on self-supervised learning has led to considerable progress on image classification, but often with degraded transfer performance on object detection. The objective of this paper is to advance self-supervised pretrained models specifically for object detection. Based on the inherent difference between classification and detection, we propose a new self-supervised pretext task, called instance localization. Image instances are pasted at various locations and scales onto background images. The pretext task is to predict the instance category given the composited images as well as the foreground bounding boxes. We show that integration of bounding boxes into pretraining promotes better alignment between convolutional features and region boxes. In addition, we propose an augmentation method on the bounding boxes to further enhance this feature alignment. As a result, our model becomes weaker at Imagenet semantic classification but stronger at image patch localization, with an overall stronger pretrained model for object detection. Experimental results demonstrate that our approach yields state-of-the-art transfer learning results for object detection on PASCAL VOC and MSCOCO.",
  "s2id": "4f7a77d04e7e1cff1f6e306f082217be78203643",
  "twitter": {
    "retweets": 5,
    "likes": 35,
    "replies": 2
  },
  "citations": 3
}