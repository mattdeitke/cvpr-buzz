{
  "arXiv": "http://arxiv.org/abs/2103.05687",
  "title": "Capturing Omni-Range Context for Omnidirectional Segmentation",
  "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yang_Capturing_Omni-Range_Context_for_Omnidirectional_Segmentation_CVPR_2021_paper.pdf",
  "authors": [
    "Kailun Yang",
    "Jiaming Zhang",
    "Simon Reiss",
    "Xinxin Hu",
    "Rainer Stiefelhagen"
  ],
  "abstract": "Convolutional Networks (ConvNets) excel at semantic segmentation and have become a vital component for perception in autonomous driving. Enabling an all-encompassing view of street-scenes, omnidirectional cameras present themselves as a perfect fit in such systems. Most segmentation models for parsing urban environments operate on common, narrow Field of View (FoV) images. Transferring these models from the domain they were designed for to 360-degree perception, their performance drops dramatically, e.g., by an absolute 30.0% (mIoU) on established test-beds. To bridge the gap in terms of FoV and structural distribution between the imaging domains, we introduce Efficient Concurrent Attention Networks (ECANets), directly capturing the inherent long-range dependencies in omnidirectional imagery. In addition to the learned attention-based contextual priors that can stretch across 360-degree images, we upgrade model training by leveraging multi-source and omni-supervised learning, taking advantage of both: Densely labeled and unlabeled data originating from multiple datasets. To foster progress in panoramic image segmentation, we put forward and extensively evaluate models on Wild PAnoramic Semantic Segmentation (WildPASS), a dataset designed to capture diverse scenes from all around the globe. Our novel model, training regimen and multi-source prediction fusion elevate the performance (mIoU) to new state-of-the-art results on the public PASS (60.2%) and the fresh WildPASS (69.0%) benchmarks.",
  "s2id": "bf56ef26c641af5c5018cf8b9b96ed0ac00dc717",
  "twitter": {
    "retweets": 1,
    "likes": 4,
    "replies": 0,
    "ids": [
      "1371386799327612934"
    ]
  },
  "citations": 1,
  "posterSession": "Monday"
}