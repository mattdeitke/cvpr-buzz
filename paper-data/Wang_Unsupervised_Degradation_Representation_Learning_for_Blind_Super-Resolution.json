{
  "arXiv": "http://arxiv.org/abs/2104.00416",
  "title": "Unsupervised Degradation Representation Learning for Blind Super-Resolution",
  "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_Unsupervised_Degradation_Representation_Learning_for_Blind_Super-Resolution_CVPR_2021_paper.pdf",
  "authors": [
    "Longguang Wang",
    "Yingqian Wang",
    "Xiaoyu Dong",
    "Qingyu Xu",
    "Jungang Yang",
    "Wei An",
    "Yulan Guo"
  ],
  "abstract": "Most existing CNN-based super-resolution (SR) methods are developed based on an assumption that the degradation is fixed and known (e.g., bicubic downsampling). However, these methods suffer a severe performance drop when the real degradation is different from their assumption. To handle various unknown degradations in real-world applications, previous methods rely on degradation estimation to reconstruct the SR image. Nevertheless, degradation estimation methods are usually time-consuming and may lead to SR failure due to large estimation errors. In this paper, we propose an unsupervised degradation representation learning scheme for blind SR without explicit degradation estimation. Specifically, we learn abstract representations to distinguish various degradations in the representation space rather than explicit estimation in the pixel space. Moreover, we introduce a Degradation-Aware SR (DASR) network with flexible adaption to various degradations based on the learned representations. It is demonstrated that our degradation representation learning scheme can extract discriminative representations to obtain accurate degradation information. Experiments on both synthetic and real images show that our network achieves state-of-the-art performance for the blind SR task. Code is available at: https://github.com/LongguangWang/DASR.",
  "s2id": "e92817cc3eed1ec0e1a17db88bb7da9ae78dec72",
  "twitter": {
    "retweets": 0,
    "likes": 0,
    "replies": 1,
    "ids": [
      "1402978184463667203"
    ]
  },
  "citations": 0,
  "posterSession": "Wednesday"
}