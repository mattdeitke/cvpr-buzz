{
  "arXiv": "http://arxiv.org/abs/2104.01601",
  "title": "Towards Rolling Shutter Correction and Deblurring in Dynamic Scenes",
  "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Zhong_Towards_Rolling_Shutter_Correction_and_Deblurring_in_Dynamic_Scenes_CVPR_2021_paper.pdf",
  "authors": [
    "Zhihang Zhong",
    "Yinqiang Zheng",
    "Imari Sato"
  ],
  "abstract": "Joint rolling shutter correction and deblurring (RSCD) techniques are critical for the prevalent CMOS cameras. However, current approaches are still based on conventional energy optimization and are developed for static scenes. To enable learning-based approaches to address real-world RSCD problem, we contribute the first dataset, BS-RSCD, which includes both ego-motion and object-motion in dynamic scenes. Real distorted and blurry videos with corresponding ground truth are recorded simultaneously via a beam-splitter-based acquisition system. Since direct application of existing individual rolling shutter correction (RSC) or global shutter deblurring (GSD) methods on RSCD leads to undesirable results due to inherent flaws in the network architecture, we further present the first learning-based model (JCD) for RSCD. The key idea is that we adopt bi-directional warping streams for displacement compensation, while also preserving the non-warped deblurring stream for details restoration. The experimental results demonstrate that JCD achieves state-of-the-art performance on the realistic RSCD dataset (BS-RSCD) and the synthetic RSC dataset (Fastec-RS). The dataset and code are available at https://github.com/zzh-tech/RSCD.",
  "s2id": "0b1c076a9b14677e2e8ea542bbbd9a435aa534e1",
  "twitter": {
    "retweets": 1,
    "likes": 7,
    "replies": 0
  },
  "citations": 0,
  "posterSession": "Wednesday"
}