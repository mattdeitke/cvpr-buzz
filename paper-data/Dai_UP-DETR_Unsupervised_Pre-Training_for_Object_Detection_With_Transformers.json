{
  "arXiv": null,
  "title": "UP-DETR: Unsupervised Pre-Training for Object Detection With Transformers",
  "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Dai_UP-DETR_Unsupervised_Pre-Training_for_Object_Detection_With_Transformers_CVPR_2021_paper.pdf",
  "authors": [
    "Zhigang Dai",
    "Bolun Cai",
    "Yugeng Lin",
    "Junying Chen"
  ],
  "abstract": "Object detection with transformers (DETR) reaches competitive performance with Faster R-CNN via a transformer encoder-decoder architecture. Inspired by the great success of pre-training transformers in natural language processing, we propose a pretext task named random query patch detection to Unsupervisedly Pre-train DETR (UP-DETR) for object detection. Specifically, we randomly crop patches from the given image and then feed them as queries to the decoder. The model is pre-trained to detect these query patches from the original image. During the pre-training, we address two critical issues: multi-task learning and multi-query localization. (1) To trade off classification and localization preferences in the pretext task, we freeze the CNN backbone and propose a patch feature reconstruction branch which is jointly optimized with patch detection. (2) To perform multi-query localization, we introduce UP-DETR from single-query patch and extend it to multi-query patches with object query shuffle and attention mask. In our experiments, UP-DETR significantly boosts the performance of DETR with faster convergence and higher average precision on object detection, one-shot detection and panoptic segmentation. Code and pre-training models: https://github.com/dddzg/up-detr.",
  "s2id": "95d85fec8a2e9ac024b08c7d34c5f9de41f02b26",
  "twitter": {
    "retweets": 48,
    "likes": 233,
    "replies": 2
  },
  "citations": 24,
  "posterSession": "Monday"
}