{
  "arXiv": null,
  "title": "S3: Learnable Sparse Signal Superdensity for Guided Depth Estimation",
  "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Huang_S3_Learnable_Sparse_Signal_Superdensity_for_Guided_Depth_Estimation_CVPR_2021_paper.pdf",
  "authors": [
    "Yu-Kai Huang",
    "Yueh-Cheng Liu",
    "Tsung-Han Wu",
    "Hung-Ting Su",
    "Yu-Cheng Chang",
    "Tsung-Lin Tsou",
    "Yu-An Wang",
    "Winston H. Hsu"
  ],
  "abstract": "Dense depth estimation plays a key role in multiple applications such as robotics, 3D reconstruction, and augmented reality. While sparse signal, e.g., LiDAR and Radar, has been leveraged as guidance for enhancing dense depth estimation, the improvement is limited due to its low density and imbalanced distribution. To maximize the utility from the sparse source, we propose Sparse Signal Superdensity (S3) technique, which expands the depth value from sparse cues while estimating the confidence of expanded region. The proposed S3 can be applied to various guided depth estimation approaches and trained end-to-end at different stages, including input, cost volume and output. Extensive experiments demonstrate the effectiveness, robustness, and flexibility of the S3 technique on LiDAR and Radar signal.",
  "s2id": "4c4822142023a68729f7351a55b40225c8d6d694",
  "citations": 0
}