{
  "arXiv": "http://arxiv.org/abs/2012.09365",
  "title": "Learning To Recover 3D Scene Shape From a Single Image",
  "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Yin_Learning_To_Recover_3D_Scene_Shape_From_a_Single_Image_CVPR_2021_paper.pdf",
  "authors": [
    "Wei Yin",
    "Jianming Zhang",
    "Oliver Wang",
    "Simon Niklaus",
    "Long Mai",
    "Simon Chen",
    "Chunhua Shen"
  ],
  "abstract": "Despite significant progress in monocular depth estimation in the wild, recent state-of-the-art methods cannot be used to recover accurate 3D scene shape due to an unknown depth shift induced by shift-invariant reconstruction losses used in mixed-data depth prediction training, and possible unknown camera focal length. We investigate this problem in detail and propose a two-stage framework that first predicts depth up to an unknown scale and shift from a single monocular image, and then use 3D point cloud encoders to predict the missing depth shift and focal length that allow us to recover a realistic 3D scene shape. In addition, we propose an image-level normalized regression loss and a normal-based geometry loss to enhance depth prediction models trained on mixed datasets. We test our depth model on nine unseen datasets and achieve state-of-the-art performance on zero-shot dataset generalization. Code is available at:https://git.io/Depth.",
  "s2id": "4ac318309807b5a7a50a1a292ced43e6f5f0ffbb",
  "twitter": {
    "retweets": 30,
    "likes": 136,
    "replies": 3
  },
  "citations": 2
}