{
  "arXiv": "http://arxiv.org/abs/2103.13660",
  "title": "Closing the Loop: Joint Rain Generation and Removal via Disentangled Image Translation",
  "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Ye_Closing_the_Loop_Joint_Rain_Generation_and_Removal_via_Disentangled_CVPR_2021_paper.pdf",
  "authors": [
    "Yuntong Ye",
    "Yi Chang",
    "Hanyu Zhou",
    "Luxin Yan"
  ],
  "abstract": "Existing deep learning-based image deraining methods have achieved promising performance for synthetic rainy images, typically rely on the pairs of sharp images and simulated rainy counterparts. However, these methods suffer from significant performance drop when facing the real rain, because of the huge gap between the simplified synthetic rain and the complex real rain. In this work, we argue that the rain generation and removal are the two sides of the same coin and should be tightly coupled. To close the loop, we propose to jointly learn real rain generation and removal procedure within a unified disentangled image translation framework. Specifically, we propose a bidirectional disentangled translation network, in which each unidirectional network contains two loops of joint rain generation and removal for both the real and synthetic rain image, respectively. Meanwhile, we enforce the disentanglement strategy by decomposing the rainy image into a clean background and rain layer (rain removal), in order to better preserve the identity background via both the cycle-consistency loss and adversarial loss, and ease the rain layer translating between the real and synthetic rainy image. A counterpart composition with the entanglement strategy is symmetrically applied for rain generation. Extensive experiments on synthetic and real-world rain datasets show the superiority of proposed method compared to state-of-the-arts.",
  "s2id": "d033c802467b2dd8e91a69abaf62a2e5b941d3a6",
  "twitter": {
    "retweets": 1,
    "likes": 6,
    "replies": 0
  },
  "citations": 0,
  "posterSession": "Monday"
}