{
  "arXiv": "http://arxiv.org/abs/2103.05086",
  "title": "How Privacy-Preserving Are Line Clouds? Recovering Scene Details From 3D Lines",
  "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Chelani_How_Privacy-Preserving_Are_Line_Clouds_Recovering_Scene_Details_From_3D_CVPR_2021_paper.pdf",
  "authors": [
    "Kunal Chelani",
    "Fredrik Kahl",
    "Torsten Sattler"
  ],
  "abstract": "Visual localization is the problem of estimating the camera pose of a given image with respect to a known scene. Visual localization algorithms are a fundamental building block in advanced computer vision applications, including Mixed and Virtual Reality systems. Many algorithms used in practice represent the scene through a Structure-from-Motion (SfM) point cloud, where each 3D point is associated with one or more local image features. Establishing 2D-3D matches between features in a query image and the 3D points through descriptor matching Visual localization is the problem of estimating the camera pose of a given image with respect to a known scene. Visual localization algorithms are a fundamental building block in advanced computer vision applications, including Mixed and Virtual Reality systems. Many algorithms used in practice represent the scene through a Structure-from-Motion (SfM) point cloud and use 2D-3D matches between a query image and the 3D points for camera pose estimation. As recently shown, image details can be accurately recovered from SfM point clouds by translating renderings of the sparse point clouds to images. To address the resulting potential privacy risks for user-generated content, it was recently proposed to lift point clouds to line clouds by replacing 3D points by randomly oriented 3D lines passing through these points. The resulting representation is unintelligible to humans and effectively prevents point cloud-to-image translation. This paper shows that a significant amount of information about the 3D scene geometry is preserved in these line clouds, allowing us to (approximately) recover the 3D point positions and thus to (approximately) recover image content. Our approach is based on the observation that the closest points between lines can yield a good approximation to the original 3D points. Code is available at \\href https://github.com/kunalchelani/Line2Point  https://github.com/kunalchelani/Line2Point .",
  "s2id": "4de17fe5c301e90062c8edad26c91ab7867913df",
  "twitter": {
    "retweets": 11,
    "likes": 75,
    "replies": 2,
    "ids": [
      "1369950352926244867",
      "1371084731236765698",
      "1371266600226066433"
    ]
  },
  "citations": 0,
  "posterSession": "Friday"
}