{
  "arXiv": "http://arxiv.org/abs/2101.06549",
  "title": "AdvSim: Generating Safety-Critical Scenarios for Self-Driving Vehicles",
  "pdf": "https://openaccess.thecvf.com/content/CVPR2021/papers/Wang_AdvSim_Generating_Safety-Critical_Scenarios_for_Self-Driving_Vehicles_CVPR_2021_paper.pdf",
  "authors": [
    "Jingkang Wang",
    "Ava Pun",
    "James Tu",
    "Sivabalan Manivasagam",
    "Abbas Sadat",
    "Sergio Casas",
    "Mengye Ren",
    "Raquel Urtasun"
  ],
  "abstract": "As self-driving systems become better, simulating scenarios where the autonomy stack may fail becomes more important. Traditionally, those scenarios are generated for a few scenes with respect to the planning module that takes ground-truth actor states as input. This does not scale and cannot identify all possible autonomy failures, such as perception failures due to occlusion. In this paper, we propose AdvSim, an adversarial framework to generate safety-critical scenarios for any LiDAR-based autonomy system. Given an initial traffic scenario, AdvSim modifies the actors' trajectories in a physically plausible manner and updates the LiDAR sensor data to match the perturbed world. Importantly, by simulating directly from sensor data, we obtain adversarial scenarios that are safety-critical for the full autonomy stack. Our experiments show that our approach is general and can identify thousands of semantically meaningful safety-critical scenarios for a wide range of modern self-driving systems. Furthermore, we show that the robustness and safety of these systems can be further improved by training them with scenarios generated by AdvSim.",
  "s2id": "5564a500f96696be53944d69fc78d67ba4c915d1",
  "twitter": {
    "retweets": 0,
    "likes": 0,
    "replies": 2
  },
  "citations": 0
}